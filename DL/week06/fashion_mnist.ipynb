{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator() if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.linear_relu_stack = nn.Sequential(\n",
    "\t\t\tnn.Linear(28 * 28, 512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, 512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, 10)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tlogits = self.linear_relu_stack(x)\n",
    "\t\treturn logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Loss {loss}, {current}/{size}\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            correct += (pred.argmax(1) == y).sum().item() # changed\n",
    "    \n",
    "    accuracy = correct / size\n",
    "    print(f\"Accuracy {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluation (with checkpointing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Loss 2.293273448944092, 64/60000\n",
      "Loss 2.235753059387207, 6464/60000\n",
      "Loss 2.1303515434265137, 12864/60000\n",
      "Loss 2.057518482208252, 19264/60000\n",
      "Loss 1.8624680042266846, 25664/60000\n",
      "Loss 1.667799472808838, 32064/60000\n",
      "Loss 1.5291783809661865, 38464/60000\n",
      "Loss 1.315490961074829, 44864/60000\n",
      "Loss 1.258042573928833, 51264/60000\n",
      "Loss 1.1035103797912598, 57664/60000\n",
      "Accuracy 65.29%\n",
      "Epoch 2\n",
      "Loss 1.168516993522644, 64/60000\n",
      "Loss 1.115630865097046, 6464/60000\n",
      "Loss 0.8857837915420532, 12864/60000\n",
      "Loss 0.9927456378936768, 19264/60000\n",
      "Loss 0.8557217121124268, 25664/60000\n",
      "Loss 0.8570118546485901, 32064/60000\n",
      "Loss 0.8965393900871277, 38464/60000\n",
      "Loss 0.8217214345932007, 44864/60000\n",
      "Loss 0.8368729948997498, 51264/60000\n",
      "Loss 0.7918344140052795, 57664/60000\n",
      "Accuracy 71.2%\n",
      "Epoch 3\n",
      "Loss 0.7929809093475342, 64/60000\n",
      "Loss 0.8663868308067322, 6464/60000\n",
      "Loss 0.6117939949035645, 12864/60000\n",
      "Loss 0.8067803978919983, 19264/60000\n",
      "Loss 0.7039192914962769, 25664/60000\n",
      "Loss 0.695603609085083, 32064/60000\n",
      "Loss 0.7590861320495605, 38464/60000\n",
      "Loss 0.7234920263290405, 44864/60000\n",
      "Loss 0.7281880974769592, 51264/60000\n",
      "Loss 0.6912521123886108, 57664/60000\n",
      "Accuracy 75.83%\n",
      "Epoch 4\n",
      "Loss 0.6494831442832947, 64/60000\n",
      "Loss 0.7500959634780884, 6464/60000\n",
      "Loss 0.5030180811882019, 12864/60000\n",
      "Loss 0.7298033237457275, 19264/60000\n",
      "Loss 0.6329452991485596, 25664/60000\n",
      "Loss 0.6309868097305298, 32064/60000\n",
      "Loss 0.6734609007835388, 38464/60000\n",
      "Loss 0.6702853441238403, 44864/60000\n",
      "Loss 0.6745815277099609, 51264/60000\n",
      "Loss 0.6274943351745605, 57664/60000\n",
      "Accuracy 78.24%\n",
      "Epoch 5\n",
      "Loss 0.5668830871582031, 64/60000\n",
      "Loss 0.6711949110031128, 6464/60000\n",
      "Loss 0.44097626209259033, 12864/60000\n",
      "Loss 0.6774759292602539, 19264/60000\n",
      "Loss 0.5890765190124512, 25664/60000\n",
      "Loss 0.5956325531005859, 32064/60000\n",
      "Loss 0.6165046691894531, 38464/60000\n",
      "Loss 0.6451830863952637, 44864/60000\n",
      "Loss 0.6497763395309448, 51264/60000\n",
      "Loss 0.5812154412269592, 57664/60000\n",
      "Accuracy 79.62%\n",
      "Epoch 6\n",
      "Loss 0.5126081109046936, 64/60000\n",
      "Loss 0.6165051460266113, 6464/60000\n",
      "Loss 0.4013269245624542, 12864/60000\n",
      "Loss 0.6383129358291626, 19264/60000\n",
      "Loss 0.5546911954879761, 25664/60000\n",
      "Loss 0.5704392790794373, 32064/60000\n",
      "Loss 0.5775539875030518, 38464/60000\n",
      "Loss 0.6376493573188782, 44864/60000\n",
      "Loss 0.6376746296882629, 51264/60000\n",
      "Loss 0.5427566766738892, 57664/60000\n",
      "Accuracy 80.62%\n",
      "Epoch 7\n",
      "Loss 0.47132349014282227, 64/60000\n",
      "Loss 0.5780494213104248, 6464/60000\n",
      "Loss 0.3742784857749939, 12864/60000\n",
      "Loss 0.6072484254837036, 19264/60000\n",
      "Loss 0.5230350494384766, 25664/60000\n",
      "Loss 0.5480302572250366, 32064/60000\n",
      "Loss 0.5500302314758301, 38464/60000\n",
      "Loss 0.637600302696228, 44864/60000\n",
      "Loss 0.6283431053161621, 51264/60000\n",
      "Loss 0.5091545581817627, 57664/60000\n",
      "Accuracy 81.28%\n",
      "Epoch 8\n",
      "Loss 0.4383396506309509, 64/60000\n",
      "Loss 0.5505344271659851, 6464/60000\n",
      "Loss 0.3541830778121948, 12864/60000\n",
      "Loss 0.5816493630409241, 19264/60000\n",
      "Loss 0.4942120909690857, 25664/60000\n",
      "Loss 0.5281440019607544, 32064/60000\n",
      "Loss 0.5298090577125549, 38464/60000\n",
      "Loss 0.6379799842834473, 44864/60000\n",
      "Loss 0.6191184520721436, 51264/60000\n",
      "Loss 0.48148345947265625, 57664/60000\n",
      "Accuracy 81.63%\n",
      "Epoch 9\n",
      "Loss 0.41099050641059875, 64/60000\n",
      "Loss 0.5303100943565369, 6464/60000\n",
      "Loss 0.3385613262653351, 12864/60000\n",
      "Loss 0.5605858564376831, 19264/60000\n",
      "Loss 0.4698575437068939, 25664/60000\n",
      "Loss 0.5109230875968933, 32064/60000\n",
      "Loss 0.5140562057495117, 38464/60000\n",
      "Loss 0.6359527707099915, 44864/60000\n",
      "Loss 0.609268307685852, 51264/60000\n",
      "Loss 0.46014589071273804, 57664/60000\n",
      "Accuracy 81.92%\n",
      "Epoch 10\n",
      "Loss 0.38840287923812866, 64/60000\n",
      "Loss 0.5151762366294861, 6464/60000\n",
      "Loss 0.32556629180908203, 12864/60000\n",
      "Loss 0.5434450507164001, 19264/60000\n",
      "Loss 0.4496588408946991, 25664/60000\n",
      "Loss 0.49644604325294495, 32064/60000\n",
      "Loss 0.5017889142036438, 38464/60000\n",
      "Loss 0.631237268447876, 44864/60000\n",
      "Loss 0.5990572571754456, 51264/60000\n",
      "Loss 0.4441364109516144, 57664/60000\n",
      "Accuracy 82.28%\n",
      "Epoch 11\n",
      "Loss 0.3684513568878174, 64/60000\n",
      "Loss 0.5030229091644287, 6464/60000\n",
      "Loss 0.3146771192550659, 12864/60000\n",
      "Loss 0.5288578867912292, 19264/60000\n",
      "Loss 0.4329235851764679, 25664/60000\n",
      "Loss 0.4844770133495331, 32064/60000\n",
      "Loss 0.4913622736930847, 38464/60000\n",
      "Loss 0.6242799162864685, 44864/60000\n",
      "Loss 0.5890415906906128, 51264/60000\n",
      "Loss 0.4321291744709015, 57664/60000\n",
      "Accuracy 82.64%\n",
      "Epoch 12\n",
      "Loss 0.35130712389945984, 64/60000\n",
      "Loss 0.4930340051651001, 6464/60000\n",
      "Loss 0.3052327632904053, 12864/60000\n",
      "Loss 0.5165401101112366, 19264/60000\n",
      "Loss 0.41907060146331787, 25664/60000\n",
      "Loss 0.47468388080596924, 32064/60000\n",
      "Loss 0.4824206531047821, 38464/60000\n",
      "Loss 0.6160274744033813, 44864/60000\n",
      "Loss 0.5795708298683167, 51264/60000\n",
      "Loss 0.42303982377052307, 57664/60000\n",
      "Accuracy 82.87%\n",
      "Epoch 13\n",
      "Loss 0.33600422739982605, 64/60000\n",
      "Loss 0.4843582212924957, 6464/60000\n",
      "Loss 0.2970811128616333, 12864/60000\n",
      "Loss 0.5067212581634521, 19264/60000\n",
      "Loss 0.4069770574569702, 25664/60000\n",
      "Loss 0.4663720726966858, 32064/60000\n",
      "Loss 0.47411903738975525, 38464/60000\n",
      "Loss 0.6079047918319702, 44864/60000\n",
      "Loss 0.5708985924720764, 51264/60000\n",
      "Loss 0.41557034850120544, 57664/60000\n",
      "Accuracy 83.05%\n",
      "Epoch 14\n",
      "Loss 0.32292938232421875, 64/60000\n",
      "Loss 0.4764946699142456, 6464/60000\n",
      "Loss 0.28990137577056885, 12864/60000\n",
      "Loss 0.49866002798080444, 19264/60000\n",
      "Loss 0.3961489498615265, 25664/60000\n",
      "Loss 0.4595375657081604, 32064/60000\n",
      "Loss 0.466525673866272, 38464/60000\n",
      "Loss 0.5999102592468262, 44864/60000\n",
      "Loss 0.5627870559692383, 51264/60000\n",
      "Loss 0.4098665714263916, 57664/60000\n",
      "Accuracy 83.22%\n",
      "Epoch 15\n",
      "Loss 0.3114621639251709, 64/60000\n",
      "Loss 0.46920478343963623, 6464/60000\n",
      "Loss 0.28338682651519775, 12864/60000\n",
      "Loss 0.49178317189216614, 19264/60000\n",
      "Loss 0.3866073489189148, 25664/60000\n",
      "Loss 0.4536125957965851, 32064/60000\n",
      "Loss 0.45980533957481384, 38464/60000\n",
      "Loss 0.5919933319091797, 44864/60000\n",
      "Loss 0.555694580078125, 51264/60000\n",
      "Loss 0.40531742572784424, 57664/60000\n",
      "Accuracy 83.44%\n",
      "Epoch 16\n",
      "Loss 0.3016316890716553, 64/60000\n",
      "Loss 0.46216851472854614, 6464/60000\n",
      "Loss 0.2776699662208557, 12864/60000\n",
      "Loss 0.48558759689331055, 19264/60000\n",
      "Loss 0.3777136206626892, 25664/60000\n",
      "Loss 0.44793248176574707, 32064/60000\n",
      "Loss 0.45338284969329834, 38464/60000\n",
      "Loss 0.584786057472229, 44864/60000\n",
      "Loss 0.5492587089538574, 51264/60000\n",
      "Loss 0.40148526430130005, 57664/60000\n",
      "Accuracy 83.61%\n",
      "Epoch 17\n",
      "Loss 0.293290913105011, 64/60000\n",
      "Loss 0.45496565103530884, 6464/60000\n",
      "Loss 0.2722531855106354, 12864/60000\n",
      "Loss 0.47960418462753296, 19264/60000\n",
      "Loss 0.3694438934326172, 25664/60000\n",
      "Loss 0.441752552986145, 32064/60000\n",
      "Loss 0.4470263123512268, 38464/60000\n",
      "Loss 0.5772854089736938, 44864/60000\n",
      "Loss 0.5425105094909668, 51264/60000\n",
      "Loss 0.39847779273986816, 57664/60000\n",
      "Accuracy 83.74000000000001%\n",
      "Epoch 18\n",
      "Loss 0.28630781173706055, 64/60000\n",
      "Loss 0.44902503490448, 6464/60000\n",
      "Loss 0.2675246596336365, 12864/60000\n",
      "Loss 0.47417783737182617, 19264/60000\n",
      "Loss 0.36260244250297546, 25664/60000\n",
      "Loss 0.4358915686607361, 32064/60000\n",
      "Loss 0.4387105405330658, 38464/60000\n",
      "Loss 0.5692651271820068, 44864/60000\n",
      "Loss 0.5361895561218262, 51264/60000\n",
      "Loss 0.39574894309043884, 57664/60000\n",
      "Accuracy 83.83%\n",
      "Epoch 19\n",
      "Loss 0.28050005435943604, 64/60000\n",
      "Loss 0.442470908164978, 6464/60000\n",
      "Loss 0.2633019983768463, 12864/60000\n",
      "Loss 0.46909016370773315, 19264/60000\n",
      "Loss 0.3552584648132324, 25664/60000\n",
      "Loss 0.4301280975341797, 32064/60000\n",
      "Loss 0.4336202144622803, 38464/60000\n",
      "Loss 0.5642361044883728, 44864/60000\n",
      "Loss 0.530922532081604, 51264/60000\n",
      "Loss 0.39366090297698975, 57664/60000\n",
      "Accuracy 83.88%\n",
      "Epoch 20\n",
      "Loss 0.2752988934516907, 64/60000\n",
      "Loss 0.4361473023891449, 6464/60000\n",
      "Loss 0.25964444875717163, 12864/60000\n",
      "Loss 0.4640042185783386, 19264/60000\n",
      "Loss 0.3483884334564209, 25664/60000\n",
      "Loss 0.4246126413345337, 32064/60000\n",
      "Loss 0.42856845259666443, 38464/60000\n",
      "Loss 0.5589359998703003, 44864/60000\n",
      "Loss 0.5248451232910156, 51264/60000\n",
      "Loss 0.39171984791755676, 57664/60000\n",
      "Accuracy 84.05%\n",
      "Epoch 21\n",
      "Loss 0.2711523175239563, 64/60000\n",
      "Loss 0.43017303943634033, 6464/60000\n",
      "Loss 0.2566099464893341, 12864/60000\n",
      "Loss 0.45942696928977966, 19264/60000\n",
      "Loss 0.3427465260028839, 25664/60000\n",
      "Loss 0.41938644647598267, 32064/60000\n",
      "Loss 0.4236849546432495, 38464/60000\n",
      "Loss 0.5536748766899109, 44864/60000\n",
      "Loss 0.5186871290206909, 51264/60000\n",
      "Loss 0.38962769508361816, 57664/60000\n",
      "Accuracy 84.21%\n",
      "Epoch 22\n",
      "Loss 0.2674776017665863, 64/60000\n",
      "Loss 0.4245084822177887, 6464/60000\n",
      "Loss 0.25378116965293884, 12864/60000\n",
      "Loss 0.4544503390789032, 19264/60000\n",
      "Loss 0.33717629313468933, 25664/60000\n",
      "Loss 0.41440385580062866, 32064/60000\n",
      "Loss 0.41853925585746765, 38464/60000\n",
      "Loss 0.5486273765563965, 44864/60000\n",
      "Loss 0.5135607123374939, 51264/60000\n",
      "Loss 0.3875672221183777, 57664/60000\n",
      "Accuracy 84.33%\n",
      "Epoch 23\n",
      "Loss 0.2637627124786377, 64/60000\n",
      "Loss 0.41948312520980835, 6464/60000\n",
      "Loss 0.2511569559574127, 12864/60000\n",
      "Loss 0.44970041513442993, 19264/60000\n",
      "Loss 0.33171138167381287, 25664/60000\n",
      "Loss 0.4087046980857849, 32064/60000\n",
      "Loss 0.41369348764419556, 38464/60000\n",
      "Loss 0.543826699256897, 44864/60000\n",
      "Loss 0.5083751678466797, 51264/60000\n",
      "Loss 0.38589465618133545, 57664/60000\n",
      "Accuracy 84.5%\n",
      "Epoch 24\n",
      "Loss 0.26056981086730957, 64/60000\n",
      "Loss 0.4148421883583069, 6464/60000\n",
      "Loss 0.24776147305965424, 12864/60000\n",
      "Loss 0.44505205750465393, 19264/60000\n",
      "Loss 0.32672998309135437, 25664/60000\n",
      "Loss 0.40320292115211487, 32064/60000\n",
      "Loss 0.4086252450942993, 38464/60000\n",
      "Loss 0.5389070510864258, 44864/60000\n",
      "Loss 0.5035553574562073, 51264/60000\n",
      "Loss 0.3841968774795532, 57664/60000\n",
      "Accuracy 84.61%\n",
      "Epoch 25\n",
      "Loss 0.2578777074813843, 64/60000\n",
      "Loss 0.41021695733070374, 6464/60000\n",
      "Loss 0.24578136205673218, 12864/60000\n",
      "Loss 0.4404836595058441, 19264/60000\n",
      "Loss 0.32170069217681885, 25664/60000\n",
      "Loss 0.3985637128353119, 32064/60000\n",
      "Loss 0.40383875370025635, 38464/60000\n",
      "Loss 0.534142017364502, 44864/60000\n",
      "Loss 0.49884840846061707, 51264/60000\n",
      "Loss 0.3828280568122864, 57664/60000\n",
      "Accuracy 84.69%\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-3)\n",
    "\n",
    "epochs = 25\n",
    "for e in range(1, epochs + 1):\n",
    "    print(f\"Epoch {e}\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "\n",
    "    torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": e\n",
    "    }, \"models/fashion_mnist_checkpoint.pth\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to fashion_mnist.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"models/fashion_mnist.pth\")\n",
    "print(\"Saved PyTorch Model State to fashion_mnist.pth\")\n",
    "\n",
    "# load model\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"models/fashion_mnist.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred.argmax(1)], classes[y]\n",
    "    \n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
