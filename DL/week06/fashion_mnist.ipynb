{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator() if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.linear_relu_stack = nn.Sequential(\n",
    "\t\t\tnn.Linear(28 * 28, 512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, 512),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, 10)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tlogits = self.linear_relu_stack(x)\n",
    "\t\treturn logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Loss 2.3020429611206055, 64/60000\n",
      "Loss 2.2355735301971436, 6464/60000\n",
      "Loss 2.116560697555542, 12864/60000\n",
      "Loss 2.046175003051758, 19264/60000\n",
      "Loss 1.807072639465332, 25664/60000\n",
      "Loss 1.5927603244781494, 32064/60000\n",
      "Loss 1.477236270904541, 38464/60000\n",
      "Loss 1.277694582939148, 44864/60000\n",
      "Loss 1.2439918518066406, 51264/60000\n",
      "Loss 1.1137232780456543, 57664/60000\n",
      "Accuracy 64.0%\n",
      "Epoch 2\n",
      "Loss 1.1698213815689087, 64/60000\n",
      "Loss 1.1216623783111572, 6464/60000\n",
      "Loss 0.8906809687614441, 12864/60000\n",
      "Loss 1.020061731338501, 19264/60000\n",
      "Loss 0.8669078350067139, 25664/60000\n",
      "Loss 0.8494848608970642, 32064/60000\n",
      "Loss 0.9061334133148193, 38464/60000\n",
      "Loss 0.8234967589378357, 44864/60000\n",
      "Loss 0.8455162048339844, 51264/60000\n",
      "Loss 0.815065860748291, 57664/60000\n",
      "Accuracy 70.67999999999999%\n",
      "Epoch 3\n",
      "Loss 0.7999089956283569, 64/60000\n",
      "Loss 0.872059166431427, 6464/60000\n",
      "Loss 0.6142821311950684, 12864/60000\n",
      "Loss 0.829664945602417, 19264/60000\n",
      "Loss 0.7079451084136963, 25664/60000\n",
      "Loss 0.6779768466949463, 32064/60000\n",
      "Loss 0.7663456201553345, 38464/60000\n",
      "Loss 0.7303852438926697, 44864/60000\n",
      "Loss 0.7428596019744873, 51264/60000\n",
      "Loss 0.7094680070877075, 57664/60000\n",
      "Accuracy 75.4%\n",
      "Epoch 4\n",
      "Loss 0.6536378860473633, 64/60000\n",
      "Loss 0.7485041618347168, 6464/60000\n",
      "Loss 0.5008982419967651, 12864/60000\n",
      "Loss 0.7486194968223572, 19264/60000\n",
      "Loss 0.6385550498962402, 25664/60000\n",
      "Loss 0.6067540645599365, 32064/60000\n",
      "Loss 0.6754715442657471, 38464/60000\n",
      "Loss 0.6777478456497192, 44864/60000\n",
      "Loss 0.6912229657173157, 51264/60000\n",
      "Loss 0.6412144899368286, 57664/60000\n",
      "Accuracy 78.2%\n",
      "Epoch 5\n",
      "Loss 0.5659356117248535, 64/60000\n",
      "Loss 0.6636452674865723, 6464/60000\n",
      "Loss 0.43553251028060913, 12864/60000\n",
      "Loss 0.693242073059082, 19264/60000\n",
      "Loss 0.5983543395996094, 25664/60000\n",
      "Loss 0.5680354237556458, 32064/60000\n",
      "Loss 0.6105738282203674, 38464/60000\n",
      "Loss 0.649887204170227, 44864/60000\n",
      "Loss 0.6640411615371704, 51264/60000\n",
      "Loss 0.5906691551208496, 57664/60000\n",
      "Accuracy 79.64%\n",
      "Epoch 6\n",
      "Loss 0.5082024931907654, 64/60000\n",
      "Loss 0.606924295425415, 6464/60000\n",
      "Loss 0.394517183303833, 12864/60000\n",
      "Loss 0.6510437726974487, 19264/60000\n",
      "Loss 0.5680691003799438, 25664/60000\n",
      "Loss 0.5436798930168152, 32064/60000\n",
      "Loss 0.5658543705940247, 38464/60000\n",
      "Loss 0.6400237083435059, 44864/60000\n",
      "Loss 0.6497432589530945, 51264/60000\n",
      "Loss 0.5490427613258362, 57664/60000\n",
      "Accuracy 80.52%\n",
      "Epoch 7\n",
      "Loss 0.4659610688686371, 64/60000\n",
      "Loss 0.5679370164871216, 6464/60000\n",
      "Loss 0.36692631244659424, 12864/60000\n",
      "Loss 0.6173864603042603, 19264/60000\n",
      "Loss 0.539621114730835, 25664/60000\n",
      "Loss 0.5234867334365845, 32064/60000\n",
      "Loss 0.5342362523078918, 38464/60000\n",
      "Loss 0.6388324499130249, 44864/60000\n",
      "Loss 0.6394005417823792, 51264/60000\n",
      "Loss 0.5134946703910828, 57664/60000\n",
      "Accuracy 81.32000000000001%\n",
      "Epoch 8\n",
      "Loss 0.43285202980041504, 64/60000\n",
      "Loss 0.5401312708854675, 6464/60000\n",
      "Loss 0.3473869860172272, 12864/60000\n",
      "Loss 0.5897660851478577, 19264/60000\n",
      "Loss 0.5133758187294006, 25664/60000\n",
      "Loss 0.5050246715545654, 32064/60000\n",
      "Loss 0.5103669762611389, 38464/60000\n",
      "Loss 0.6393176317214966, 44864/60000\n",
      "Loss 0.6287844777107239, 51264/60000\n",
      "Loss 0.4839212894439697, 57664/60000\n",
      "Accuracy 81.91000000000001%\n",
      "Epoch 9\n",
      "Loss 0.4052870571613312, 64/60000\n",
      "Loss 0.5196712017059326, 6464/60000\n",
      "Loss 0.3325691521167755, 12864/60000\n",
      "Loss 0.5673564672470093, 19264/60000\n",
      "Loss 0.48938387632369995, 25664/60000\n",
      "Loss 0.4888862073421478, 32064/60000\n",
      "Loss 0.4924609661102295, 38464/60000\n",
      "Loss 0.6381915211677551, 44864/60000\n",
      "Loss 0.6174947619438171, 51264/60000\n",
      "Loss 0.46038249135017395, 57664/60000\n",
      "Accuracy 82.16%\n",
      "Epoch 10\n",
      "Loss 0.38163521885871887, 64/60000\n",
      "Loss 0.504101037979126, 6464/60000\n",
      "Loss 0.32004350423812866, 12864/60000\n",
      "Loss 0.5488157272338867, 19264/60000\n",
      "Loss 0.46869510412216187, 25664/60000\n",
      "Loss 0.4747702479362488, 32064/60000\n",
      "Loss 0.47835665941238403, 38464/60000\n",
      "Loss 0.6347761154174805, 44864/60000\n",
      "Loss 0.6062249541282654, 51264/60000\n",
      "Loss 0.44267287850379944, 57664/60000\n",
      "Accuracy 82.41000000000001%\n",
      "Epoch 11\n",
      "Loss 0.36096668243408203, 64/60000\n",
      "Loss 0.49149030447006226, 6464/60000\n",
      "Loss 0.30947500467300415, 12864/60000\n",
      "Loss 0.5330852270126343, 19264/60000\n",
      "Loss 0.45134592056274414, 25664/60000\n",
      "Loss 0.463410347700119, 32064/60000\n",
      "Loss 0.4665805697441101, 38464/60000\n",
      "Loss 0.6287318468093872, 44864/60000\n",
      "Loss 0.595210075378418, 51264/60000\n",
      "Loss 0.42908889055252075, 57664/60000\n",
      "Accuracy 82.59%\n",
      "Epoch 12\n",
      "Loss 0.34265851974487305, 64/60000\n",
      "Loss 0.4805378019809723, 6464/60000\n",
      "Loss 0.3003542423248291, 12864/60000\n",
      "Loss 0.5202510356903076, 19264/60000\n",
      "Loss 0.43618613481521606, 25664/60000\n",
      "Loss 0.4539473354816437, 32064/60000\n",
      "Loss 0.456748366355896, 38464/60000\n",
      "Loss 0.6210727691650391, 44864/60000\n",
      "Loss 0.584236741065979, 51264/60000\n",
      "Loss 0.4194576144218445, 57664/60000\n",
      "Accuracy 82.80999999999999%\n",
      "Epoch 13\n",
      "Loss 0.3271670639514923, 64/60000\n",
      "Loss 0.4713413119316101, 6464/60000\n",
      "Loss 0.2931141257286072, 12864/60000\n",
      "Loss 0.5095861554145813, 19264/60000\n",
      "Loss 0.42216336727142334, 25664/60000\n",
      "Loss 0.4466041922569275, 32064/60000\n",
      "Loss 0.4475514888763428, 38464/60000\n",
      "Loss 0.6126948595046997, 44864/60000\n",
      "Loss 0.5738535523414612, 51264/60000\n",
      "Loss 0.412179172039032, 57664/60000\n",
      "Accuracy 83.11%\n",
      "Epoch 14\n",
      "Loss 0.3144413232803345, 64/60000\n",
      "Loss 0.46300435066223145, 6464/60000\n",
      "Loss 0.2863677740097046, 12864/60000\n",
      "Loss 0.5009452104568481, 19264/60000\n",
      "Loss 0.40972447395324707, 25664/60000\n",
      "Loss 0.4400256872177124, 32064/60000\n",
      "Loss 0.4393499195575714, 38464/60000\n",
      "Loss 0.6043053269386292, 44864/60000\n",
      "Loss 0.5651417970657349, 51264/60000\n",
      "Loss 0.40607714653015137, 57664/60000\n",
      "Accuracy 83.24000000000001%\n",
      "Epoch 15\n",
      "Loss 0.3030936121940613, 64/60000\n",
      "Loss 0.4550311267375946, 6464/60000\n",
      "Loss 0.2804216146469116, 12864/60000\n",
      "Loss 0.4935113787651062, 19264/60000\n",
      "Loss 0.39815425872802734, 25664/60000\n",
      "Loss 0.43451064825057983, 32064/60000\n",
      "Loss 0.4322061240673065, 38464/60000\n",
      "Loss 0.5963898301124573, 44864/60000\n",
      "Loss 0.5569922924041748, 51264/60000\n",
      "Loss 0.4013221859931946, 57664/60000\n",
      "Accuracy 83.3%\n",
      "Epoch 16\n",
      "Loss 0.2934499979019165, 64/60000\n",
      "Loss 0.44752103090286255, 6464/60000\n",
      "Loss 0.275142103433609, 12864/60000\n",
      "Loss 0.48637038469314575, 19264/60000\n",
      "Loss 0.38798758387565613, 25664/60000\n",
      "Loss 0.42910534143447876, 32064/60000\n",
      "Loss 0.4255845546722412, 38464/60000\n",
      "Loss 0.588634192943573, 44864/60000\n",
      "Loss 0.5495321750640869, 51264/60000\n",
      "Loss 0.3972269892692566, 57664/60000\n",
      "Accuracy 83.56%\n",
      "Epoch 17\n",
      "Loss 0.28499943017959595, 64/60000\n",
      "Loss 0.44072675704956055, 6464/60000\n",
      "Loss 0.27037960290908813, 12864/60000\n",
      "Loss 0.4793252646923065, 19264/60000\n",
      "Loss 0.3782915771007538, 25664/60000\n",
      "Loss 0.42397385835647583, 32064/60000\n",
      "Loss 0.4194180965423584, 38464/60000\n",
      "Loss 0.5809432864189148, 44864/60000\n",
      "Loss 0.5429395437240601, 51264/60000\n",
      "Loss 0.3944208025932312, 57664/60000\n",
      "Accuracy 83.8%\n",
      "Epoch 18\n",
      "Loss 0.2781815528869629, 64/60000\n",
      "Loss 0.43395909667015076, 6464/60000\n",
      "Loss 0.2660854458808899, 12864/60000\n",
      "Loss 0.472682386636734, 19264/60000\n",
      "Loss 0.3692440986633301, 25664/60000\n",
      "Loss 0.4190220832824707, 32064/60000\n",
      "Loss 0.413850873708725, 38464/60000\n",
      "Loss 0.5735542178153992, 44864/60000\n",
      "Loss 0.5360807776451111, 51264/60000\n",
      "Loss 0.39185428619384766, 57664/60000\n",
      "Accuracy 83.93%\n",
      "Epoch 19\n",
      "Loss 0.272033154964447, 64/60000\n",
      "Loss 0.4273090958595276, 6464/60000\n",
      "Loss 0.262153685092926, 12864/60000\n",
      "Loss 0.4664503335952759, 19264/60000\n",
      "Loss 0.3610270321369171, 25664/60000\n",
      "Loss 0.4143716096878052, 32064/60000\n",
      "Loss 0.4092620611190796, 38464/60000\n",
      "Loss 0.5664534568786621, 44864/60000\n",
      "Loss 0.5292918682098389, 51264/60000\n",
      "Loss 0.389884889125824, 57664/60000\n",
      "Accuracy 84.06%\n",
      "Epoch 20\n",
      "Loss 0.2663831114768982, 64/60000\n",
      "Loss 0.42070338129997253, 6464/60000\n",
      "Loss 0.25898051261901855, 12864/60000\n",
      "Loss 0.4604870080947876, 19264/60000\n",
      "Loss 0.35322362184524536, 25664/60000\n",
      "Loss 0.4103649854660034, 32064/60000\n",
      "Loss 0.40423116087913513, 38464/60000\n",
      "Loss 0.5605591535568237, 44864/60000\n",
      "Loss 0.523246169090271, 51264/60000\n",
      "Loss 0.3879612684249878, 57664/60000\n",
      "Accuracy 84.15%\n",
      "Epoch 21\n",
      "Loss 0.26105594635009766, 64/60000\n",
      "Loss 0.41474449634552, 6464/60000\n",
      "Loss 0.25575152039527893, 12864/60000\n",
      "Loss 0.45504626631736755, 19264/60000\n",
      "Loss 0.3459022045135498, 25664/60000\n",
      "Loss 0.4061429500579834, 32064/60000\n",
      "Loss 0.3989017605781555, 38464/60000\n",
      "Loss 0.5550062656402588, 44864/60000\n",
      "Loss 0.5177531242370605, 51264/60000\n",
      "Loss 0.3860741853713989, 57664/60000\n",
      "Accuracy 84.28%\n",
      "Epoch 22\n",
      "Loss 0.25677841901779175, 64/60000\n",
      "Loss 0.40915149450302124, 6464/60000\n",
      "Loss 0.25275489687919617, 12864/60000\n",
      "Loss 0.4499243497848511, 19264/60000\n",
      "Loss 0.3392685055732727, 25664/60000\n",
      "Loss 0.402023047208786, 32064/60000\n",
      "Loss 0.3935708999633789, 38464/60000\n",
      "Loss 0.5492741465568542, 44864/60000\n",
      "Loss 0.5126043558120728, 51264/60000\n",
      "Loss 0.3848119378089905, 57664/60000\n",
      "Accuracy 84.37%\n",
      "Epoch 23\n",
      "Loss 0.25318074226379395, 64/60000\n",
      "Loss 0.4037497043609619, 6464/60000\n",
      "Loss 0.2500394880771637, 12864/60000\n",
      "Loss 0.44478151202201843, 19264/60000\n",
      "Loss 0.33306559920310974, 25664/60000\n",
      "Loss 0.3979243040084839, 32064/60000\n",
      "Loss 0.38883262872695923, 38464/60000\n",
      "Loss 0.5438172817230225, 44864/60000\n",
      "Loss 0.5078543424606323, 51264/60000\n",
      "Loss 0.3834988474845886, 57664/60000\n",
      "Accuracy 84.5%\n",
      "Epoch 24\n",
      "Loss 0.2494833618402481, 64/60000\n",
      "Loss 0.3985989987850189, 6464/60000\n",
      "Loss 0.247396782040596, 12864/60000\n",
      "Loss 0.4397054612636566, 19264/60000\n",
      "Loss 0.32740622758865356, 25664/60000\n",
      "Loss 0.39387232065200806, 32064/60000\n",
      "Loss 0.384326696395874, 38464/60000\n",
      "Loss 0.5387545824050903, 44864/60000\n",
      "Loss 0.5030665397644043, 51264/60000\n",
      "Loss 0.3817910850048065, 57664/60000\n",
      "Accuracy 84.55%\n",
      "Epoch 25\n",
      "Loss 0.24607399106025696, 64/60000\n",
      "Loss 0.3935166895389557, 6464/60000\n",
      "Loss 0.24509386718273163, 12864/60000\n",
      "Loss 0.43444812297821045, 19264/60000\n",
      "Loss 0.32237276434898376, 25664/60000\n",
      "Loss 0.3905114233493805, 32064/60000\n",
      "Loss 0.3802276849746704, 38464/60000\n",
      "Loss 0.5337395071983337, 44864/60000\n",
      "Loss 0.49872520565986633, 51264/60000\n",
      "Loss 0.38033366203308105, 57664/60000\n",
      "Accuracy 84.67%\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Loss {loss}, {current}/{size}\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            correct += (pred.argmax(1) == y).sum().item() # changed\n",
    "    \n",
    "    accuracy = correct / size\n",
    "    print(f\"Accuracy {accuracy * 100}%\")\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-3)\n",
    "\n",
    "epochs = 25\n",
    "for e in range(1, epochs + 1):\n",
    "    print(f\"Epoch {e}\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"models/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"models/model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred.argmax(1)], classes[y]\n",
    "    \n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
